# AllRight-SR: å¤šç­–ç•¥ç¬¦å·å›å½’å·¥å…·ç®±

## é¡¹ç›®è¯´æ˜
AllRight-SR é›†æˆäº†å¤šç§ç¬¦å·å›å½’ç®—æ³•ï¼ŒåŒ…æ‹¬è¿›åŒ–ç®—æ³•ã€ç¨€ç–å»ºæ¨¡ã€è´å¶æ–¯æ¨æ–­ã€å¼ºåŒ–å­¦ä¹ ä»¥åŠå¤šç§æ··åˆä¼˜åŒ–æ–¹æ³•ï¼Œå¸®åŠ©ç”¨æˆ·ä»æ•°æ®ä¸­è‡ªåŠ¨å‘ç°ç¬¦åˆç‰©ç†æ„ä¹‰çš„è§£æå…¬å¼ã€‚

## ä½¿ç”¨æ–¹æ³•
ä»¥ä¸‹ç¤ºä¾‹é»˜è®¤å·²å‡†å¤‡å¥½è®­ç»ƒæ•°æ® `X` (pandas.DataFrame) å’Œç›®æ ‡ `y` (pandas.Series)ã€‚

### è¿›åŒ–ç®—æ³•ç±»
#### é—ä¼ ç¼–ç¨‹ (GP)
```python
from sisso_py.evolutionary.gp import GeneticProgramming
model = GeneticProgramming(population_size=50, n_generations=10)
model.fit(X, y, feature_names=X.columns)
pred = model.predict(X)
```

#### é—ä¼ ç®—æ³•+PSOæ··åˆ
```python
from sisso_py.evolutionary.ga_pso import GAPSORegressor
model = GAPSORegressor(generations=30)
model.fit(X, y)
pred = model.predict(X)
```

### ç¨€ç–å»ºæ¨¡ç±»
#### SISSO åŸºç¡€
```python
from sisso_py.sparse_regression.sisso import SISSORegressor
model = SISSORegressor(K=3, sis_screener='pearson', so_solver='omp')
model.fit(X, y)
```

#### SISSO ç­›é€‰å™¨: pearson
```python
SISSORegressor(sis_screener='pearson').fit(X, y)
```

#### SISSO ç­›é€‰å™¨: f_regression
```python
SISSORegressor(sis_screener='f_regression').fit(X, y)
```

#### SISSO ç­›é€‰å™¨: mutual_info
```python
SISSORegressor(sis_screener='mutual_info').fit(X, y)
```

#### SISSO æ±‚è§£å™¨: omp
```python
SISSORegressor(so_solver='omp').fit(X, y)
```

#### SISSO æ±‚è§£å™¨: lasso
```python
SISSORegressor(so_solver='lasso').fit(X, y)
```

#### SISSO æ±‚è§£å™¨: elasticnet
```python
SISSORegressor(so_solver='elasticnet').fit(X, y)
```

#### SISSO ç»´åº¦æ£€æŸ¥
```python
from sisso_py.dsl.dimension import Dimension
dims = {'x1': Dimension([1,0,0,0,0,0,0])}
target_dim = Dimension([1,0,0,0,0,0,0])
SISSORegressor(dimensional_check=True).fit(X, y, feature_dimensions=dims, target_dimension=target_dim)
```

#### LASSOç¨€ç–å›å½’
```python
from sisso_py.sparse_regression.lasso_ridge_omp import LassoRegressor
model = LassoRegressor(alpha=0.01)
model.fit(X, y)
```

#### SINDy
```python
from sisso_py.sparse_regression.sindy import SINDyRegressor
model = SINDyRegressor(poly_degree=3)
model.fit(X, y)
equation = model.get_equation()
```

### è´å¶æ–¯æ¦‚ç‡ç±»
#### è´å¶æ–¯ç¬¦å·å›å½’ (MCMC)
```python
from sisso_py.probabilistic.bsr import BayesianSymbolicRegressor
model = BayesianSymbolicRegressor(n_iter=2000)
model.fit(X, y)
info = model.get_model_info()
```

#### æ¦‚ç‡ç¨‹åºå½’çº³ (PCFG)
```python
from sisso_py.probabilistic.ppi import ProbabilisticProgramInduction
model = ProbabilisticProgramInduction(n_iterations=500)
model.fit(X, y)
info = model.get_model_info()
```

### å¼ºåŒ–å­¦ä¹ ç±»
#### å¼ºåŒ–å­¦ä¹ ç¬¦å·å›å½’
```python
from sisso_py.neural_symbolic.rl_sr import ReinforcementSymbolicRegression
model = ReinforcementSymbolicRegression(max_episodes=50)
model.fit(X.values, y.values, feature_names=X.columns)
```

#### æ·±åº¦ç¬¦å·å›å½’
```python
from sisso_py.neural_symbolic.deep_sr import DeepSymbolicRegression
model = DeepSymbolicRegression(epochs=20)
model.fit(X.values, y.values, feature_names=X.columns)
```

#### ç¥ç»ç¬¦å·æ··åˆ
```python
from sisso_py.neural_symbolic.hybrid_neural import NeuralSymbolicHybrid
model = NeuralSymbolicHybrid(symbolic_component='gp')
model.fit(X.values, y.values, feature_names=X.columns)
```

### æ··åˆæ–°å…´ç±»
#### è¿›åŒ–+æ¢¯åº¦æ··åˆ
```python
from sisso_py.hybrid.evolutionary_gradient import EvolutionaryGradientHybrid
model = EvolutionaryGradientHybrid(evolution_phase_generations=10)
model.fit(X.values, y.values, feature_names=X.columns)
```

#### ç‰©ç†çº¦æŸç¬¦å·å›å½’
```python
from sisso_py.hybrid.physics_informed import PhysicsInformedSymbolicRegression
model = PhysicsInformedSymbolicRegression(dimensional_analysis=False)
model.fit(X.values, y.values, feature_names=X.columns)
```

#### å¤šç›®æ ‡ç¬¦å·å›å½’
```python
from sisso_py.hybrid.multi_objective import MultiObjectiveSymbolicRegression
model = MultiObjectiveSymbolicRegression(n_generations=10)
model.fit(X.values, y.values, feature_names=X.columns)
```

---

# SISSO-Py: Python Implementation of Sure Independence Screening and Sparsifying Operator

SISSO-Py æ˜¯ SISSOï¼ˆSure Independence Screening and Sparsifying Operatorï¼‰ç®—æ³•çš„çº¯ Python å®ç°ã€‚SISSO æ˜¯ä¸€ç§ç”¨äºç¬¦å·å›å½’å’Œç‰¹å¾å‘ç°çš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºä»æœ‰é™æ•°æ®ä¸­å‘ç°ç®€æ´ä¸”ç‰©ç†æ„ä¹‰æ˜ç¡®çš„æ•°å­¦å…¬å¼ã€‚

## ğŸŒŸ ä¸»è¦ç‰¹æ€§

- **ç¬¦å·ç‰¹å¾ç”Ÿæˆ**ï¼šé€šè¿‡ç»„åˆåŸºç¡€æ“ä½œç¬¦ç”Ÿæˆå¤æ‚çš„ç¬¦å·ç‰¹å¾
- **åˆ†å±‚å¤æ‚åº¦æ§åˆ¶**ï¼šåŸºäº K å±‚æ¶æ„ï¼Œç²¾ç¡®æ§åˆ¶ç‰¹å¾å¤æ‚åº¦
- **å¤šç§ç­›é€‰æ–¹æ³•**ï¼šæ”¯æŒçš®å°”é€Šç›¸å…³æ€§ã€äº’ä¿¡æ¯ç­‰ç‰¹å¾ç­›é€‰ç­–ç•¥
- **ç¨€ç–å»ºæ¨¡**ï¼šé›†æˆ OMPã€Lassoã€ElasticNet ç­‰ç¨€ç–å›å½’æ–¹æ³•
- **ç‰©ç†é‡çº²æ£€æŸ¥**ï¼šå¯é€‰çš„é‡çº²ä¸€è‡´æ€§éªŒè¯ï¼Œç¡®ä¿ç‰©ç†æ„ä¹‰
- **ä¸°å¯Œçš„æ“ä½œç¬¦åº“**ï¼šåŒ…å«ä»£æ•°ã€å¹‚å‡½æ•°ã€å¯¹æ•°ã€ä¸‰è§’å‡½æ•°ã€åŒæ›²å‡½æ•°ç­‰
- **è‡ªå®šä¹‰å‡½æ•°æ”¯æŒ**ï¼šæ”¯æŒç”¨æˆ·å®šä¹‰çš„è‡ªå®šä¹‰æ“ä½œç¬¦
- **å…¨é¢çš„æ—¥å¿—ç³»ç»Ÿ**ï¼šè¯¦ç»†çš„è¿è¡Œè¿‡ç¨‹è®°å½•å’Œç»“æœæŠ¥å‘Š

## ğŸ“¦ å®‰è£…

### ä¾èµ–è¦æ±‚

```python
# å¿…éœ€ä¾èµ–
numpy >= 1.19.0
scipy >= 1.7.0
scikit-learn >= 1.0.0
pandas >= 1.3.0
tqdm >= 4.60.0

# å¯é€‰ä¾èµ–
sympy >= 1.9.0  # ç”¨äºç¬¦å·è¡¨è¾¾å¼å¤„ç†
joblib >= 1.1.0  # ç”¨äºå¹¶è¡Œè®¡ç®—
numba >= 0.56.0  # ç”¨äºæ€§èƒ½åŠ é€Ÿ
```

### ğŸ”§ å¼€å‘æ¨¡å¼å®‰è£…æŒ‡å—

#### æ–¹æ³•1ï¼šæ ‡å‡†å¼€å‘æ¨¡å¼å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# 1. å…‹éš†æˆ–è¿›å…¥é¡¹ç›®ç›®å½•
git clone https://github.com/lishuzheng01/sisso-py.git
cd sisso-py

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ä½†æ¨èï¼‰
python -m venv sisso_dev
# Windows PowerShell:
sisso_dev\Scripts\Activate.ps1
# Windows CMD:
# sisso_dev\Scripts\activate.bat
# Linux/macOS:
# source sisso_dev/bin/activate

# 3. å‡çº§åŸºç¡€å·¥å…·
python -m pip install --upgrade pip setuptools wheel

# 4. å¼€å‘æ¨¡å¼å®‰è£…
pip install -e .

# 5. å®‰è£…å¼€å‘ä¾èµ–ï¼ˆå¯é€‰ï¼‰
pip install -r requirements-dev.txt

# 6. å®‰è£…å®Œæ•´åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰
pip install -e .[full]
```

#### æ–¹æ³•2ï¼šä¸€é”®å®‰è£…æ‰€æœ‰åŠŸèƒ½

```bash
# å®‰è£…åŒ…å«æ‰€æœ‰åŠŸèƒ½çš„å¼€å‘ç‰ˆæœ¬
pip install -e .[full,dev]
```

#### æ–¹æ³•3ï¼šä½¿ç”¨ç°ä»£ Python å·¥å…·é“¾

```bash
# å®‰è£… build å·¥å…·
pip install build

# æ„å»ºé¡¹ç›®
python -m build

# å¼€å‘æ¨¡å¼å®‰è£…
pip install -e .
```

### âœ¨ éªŒè¯å®‰è£…

```bash
# æµ‹è¯•å¯¼å…¥
python -c "from sisso_py import SissoRegressor; print('å®‰è£…æˆåŠŸï¼')"

# æ£€æŸ¥ç‰ˆæœ¬
python -c "import sisso_py; print('ç‰ˆæœ¬:', sisso_py.__version__)"

# è¿è¡Œå‘½ä»¤è¡Œå·¥å…·ï¼ˆå¦‚æœéœ€è¦ï¼‰
sisso-py --help
```

### ğŸ”„ å¼€å‘æ¨¡å¼çš„ä¼˜åŠ¿

- **å®æ—¶æ›´æ”¹**ï¼šä¿®æ”¹ä»£ç åæ— éœ€é‡æ–°å®‰è£…ï¼Œç›´æ¥ç”Ÿæ•ˆ
- **ä¾èµ–ç®¡ç†**ï¼šè‡ªåŠ¨å¤„ç†åŒ…ä¾èµ–å…³ç³»
- **å‘½ä»¤è¡Œå·¥å…·**ï¼šè‡ªåŠ¨å®‰è£… `sisso-py` å‘½ä»¤
- **å®Œæ•´åŠŸèƒ½**ï¼šæ”¯æŒæ‰€æœ‰å¯¼å…¥è·¯å¾„å’Œæ¨¡å—ç»“æ„

### ğŸ“ é¡¹ç›®ç»“æ„

å®‰è£…åï¼Œæ‚¨çš„é¡¹ç›®ç»“æ„åº”è¯¥æ˜¯è¿™æ ·çš„ï¼š

```
SISSO/
â”œâ”€â”€ sisso_py/                 # æºä»£ç åŒ…
â”‚   â”œâ”€â”€ __init__.py          # åŒ…åˆå§‹åŒ–ï¼ˆå«ç‰ˆæœ¬å·ï¼‰
â”‚   â”œâ”€â”€ config.py            # å…¨å±€é…ç½®
â”‚   â”œâ”€â”€ ops/                 # æ“ä½œç¬¦æ¨¡å—
â”‚   â”œâ”€â”€ dsl/                 # è¡¨è¾¾å¼è¯­è¨€
â”‚   â”œâ”€â”€ gen/                 # ç‰¹å¾ç”Ÿæˆ
â”‚   â”œâ”€â”€ sis/                 # ç­›é€‰å’Œç¨€ç–å»ºæ¨¡
â”‚   â”œâ”€â”€ metrics/             # è¯„ä¼°æŒ‡æ ‡
â”‚   â”œâ”€â”€ model/               # ä¸»è¦æ¨¡å‹
â”‚   â”œâ”€â”€ io/                  # è¾“å…¥è¾“å‡º
â”‚   â”œâ”€â”€ utils/               # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ cli.py               # å‘½ä»¤è¡Œæ¥å£
â”œâ”€â”€ setup.py                 # setuptools é…ç½®
â”œâ”€â”€ pyproject.toml           # ç°ä»£é¡¹ç›®é…ç½®
â”œâ”€â”€ requirements.txt         # è¿è¡Œä¾èµ–
â”œâ”€â”€ requirements-dev.txt     # å¼€å‘ä¾èµ–
â”œâ”€â”€ MANIFEST.in             # æ‰“åŒ…æ¸…å•
â”œâ”€â”€ LICENSE                 # è®¸å¯è¯
â”œâ”€â”€ README.md               # é¡¹ç›®æ–‡æ¡£
â””â”€â”€ sissoè®¡ç®—åº“æŠ€æœ¯æ–¹æ¡ˆ.md    # æŠ€æœ¯æ–¹æ¡ˆ
```

### ğŸ› ï¸ å¼€å‘å·¥ä½œæµ

1. **ä¿®æ”¹ä»£ç **ï¼šç›´æ¥ç¼–è¾‘ `sisso_py/` ç›®å½•ä¸‹çš„æ–‡ä»¶
2. **æµ‹è¯•ä¿®æ”¹**ï¼š

   ```bash
   python -c "from sisso_py import SissoRegressor; model = SissoRegressor()"
   ```

3. **è¿è¡Œæµ‹è¯•**ï¼š

   ```bash
   pytest tests/  # å¦‚æœæœ‰æµ‹è¯•æ–‡ä»¶
   ```

4. **ä»£ç æ ¼å¼åŒ–**ï¼š

   ```bash
   black sisso_py/
   isort sisso_py/
   ```

### ğŸ¯ é…ç½®æ–‡ä»¶è¯´æ˜

é¡¹ç›®åŒ…å«ä»¥ä¸‹é…ç½®æ–‡ä»¶ï¼š

- **`setup.py`** - ä¼ ç»Ÿçš„ setuptools é…ç½®
- **`pyproject.toml`** - ç°ä»£ Python é¡¹ç›®é…ç½®ï¼ˆPEP 518/621 æ ‡å‡†ï¼‰
- **`requirements.txt`** - è¿è¡Œæ—¶ä¾èµ–
- **`requirements-dev.txt`** - å¼€å‘ä¾èµ–
- **`MANIFEST.in`** - æ‰“åŒ…æ–‡ä»¶æ¸…å•
- **`LICENSE`** - Apache 2.0 è®¸å¯è¯

## ğŸ“š è¯¦ç»†ä½¿ç”¨æ–¹æ³•

### ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

åœ¨ä½¿ç”¨ SISSO-Py ä¹‹å‰ï¼Œäº†è§£ä»¥ä¸‹æ ¸å¿ƒæ¦‚å¿µå°†å¸®åŠ©æ‚¨æ›´å¥½åœ°é…ç½®å’Œä½¿ç”¨è¯¥åº“ï¼š

#### 1. ç¬¦å·å›å½’æµç¨‹

SISSO ç®—æ³•éµå¾ªä»¥ä¸‹æµç¨‹ï¼š

1. **ç‰¹å¾ç”Ÿæˆ**ï¼šä»åŸå§‹ç‰¹å¾å‡ºå‘ï¼Œé€šè¿‡æ“ä½œç¬¦ç»„åˆç”Ÿæˆæ–°ç‰¹å¾
2. **åˆ†å±‚æ‰©å±•**ï¼šæŒ‰å¤æ‚åº¦å±‚æ¬¡ï¼ˆKå±‚ï¼‰é€æ­¥æ‰©å±•ç‰¹å¾ç©ºé—´
3. **ç‰¹å¾ç­›é€‰ï¼ˆSISï¼‰**ï¼šä½¿ç”¨ç»Ÿè®¡æ–¹æ³•ç­›é€‰æœ€ç›¸å…³çš„ç‰¹å¾
4. **ç¨€ç–å»ºæ¨¡ï¼ˆSOï¼‰**ï¼šä½¿ç”¨ç¨€ç–å›å½’æ„å»ºæœ€ç»ˆæ¨¡å‹

#### 2. å…³é”®å‚æ•°è¯´æ˜

- **K**ï¼šæœ€å¤§å¤æ‚åº¦å±‚æ•°ï¼Œæ§åˆ¶ç‰¹å¾ç”Ÿæˆçš„æ·±åº¦
- **operators**ï¼šå¯ç”¨çš„æ•°å­¦æ“ä½œç¬¦é›†åˆ
- **sis_screener**ï¼šç‰¹å¾ç­›é€‰æ–¹æ³•ï¼ˆ'pearson'ã€'mutual_info'ï¼‰
- **sis_topk**ï¼šæ¯å±‚ä¿ç•™çš„ç‰¹å¾æ•°é‡
- **so_solver**ï¼šç¨€ç–æ±‚è§£å™¨ç±»å‹ï¼ˆ'omp'ã€'lasso'ã€'elasticnet'ï¼‰
- **so_max_terms**ï¼šæœ€ç»ˆæ¨¡å‹çš„æœ€å¤§é¡¹æ•°

### ğŸ”§ åŸºç¡€é…ç½®ä¸åˆå§‹åŒ–

#### æœ€ç®€é…ç½®

```python
from sisso_py import SissoRegressor

# ä½¿ç”¨é»˜è®¤å‚æ•°
model = SissoRegressor()
```

#### è‡ªå®šä¹‰é…ç½®

```python
model = SissoRegressor(
    K=3,                              # æœ€å¤§å¤æ‚åº¦å±‚æ•°
    operators=['+', '-', '*', 'safe_div', 'sqrt', 'square'],
    sis_screener='pearson',           # ç‰¹å¾ç­›é€‰æ–¹æ³•
    sis_topk=1000,                   # SISä¿ç•™ç‰¹å¾æ•°
    so_solver='omp',                 # ç¨€ç–æ±‚è§£å™¨
    so_max_terms=5,                  # æœ€ç»ˆæ¨¡å‹æœ€å¤§é¡¹æ•°
    cv=5,                            # äº¤å‰éªŒè¯æŠ˜æ•°
    random_state=42,                 # éšæœºç§å­
    n_jobs=-1                        # å¹¶è¡Œä½œä¸šæ•°
)
```

### ğŸ“Š æ•°æ®å‡†å¤‡ä¸å¤„ç†

#### ä» Pandas DataFrame å‡†å¤‡æ•°æ®

```python
import pandas as pd
import numpy as np

# åˆ›å»ºç¤ºä¾‹æ•°æ®
np.random.seed(42)
n_samples = 200

data = pd.DataFrame({
    'temperature': np.random.uniform(200, 400, n_samples),    # æ¸©åº¦
    'pressure': np.random.uniform(1, 10, n_samples),         # å‹å¼º
    'volume': np.random.uniform(0.1, 2, n_samples),          # ä½“ç§¯
})

# æ¨¡æ‹Ÿç†æƒ³æ°”ä½“å®šå¾‹: PV = nRT (ç®€åŒ–ä¸º P = T/V)
data['target'] = data['temperature'] / data['volume'] + np.random.normal(0, 0.1, n_samples)

# åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
X = data[['temperature', 'pressure', 'volume']]
y = data['target']
```

#### ä» NumPy æ•°ç»„å‡†å¤‡æ•°æ®

```python
from sisso_py.io import load_from_numpy

# NumPy æ•°ç»„æ•°æ®
X_np = np.random.randn(100, 4)
y_np = X_np[:, 0]**2 + X_np[:, 1] - 0.5 * X_np[:, 2] * X_np[:, 3]

# è½¬æ¢ä¸º DataFrame
X, y = load_from_numpy(X_np, y_np, feature_names=['x1', 'x2', 'x3', 'x4'])
```

#### å¤„ç†å®é™…æ•°æ®æ–‡ä»¶

```python
from sisso_py.io import load_from_pandas

# ä» CSV æ–‡ä»¶åŠ è½½
df = pd.read_csv('your_data.csv')
X, y = load_from_pandas(df, target_column='target_variable')

# æ•°æ®é¢„å¤„ç†ï¼ˆå¯é€‰ï¼‰
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = pd.DataFrame(
    scaler.fit_transform(X), 
    columns=X.columns, 
    index=X.index
)
```

### ğŸ›ï¸ æ“ä½œç¬¦é…ç½®è¯¦è§£

#### å†…ç½®æ“ä½œç¬¦å®Œæ•´åˆ—è¡¨

```python
# åŸºç¡€ä»£æ•°è¿ç®—
basic_ops = ['+', '-', '*', 'safe_div']

# å¹‚å’Œæ ¹è¿ç®—
power_ops = ['sqrt', 'cbrt', 'square', 'poly2', 'poly3']

# å¯¹æ•°å’ŒæŒ‡æ•°
log_exp_ops = ['log', 'log10', 'exp']

# ç»å¯¹å€¼å’Œç¬¦å·
abs_sign_ops = ['abs', 'sign']

# ä¸‰è§’å‡½æ•°
trig_ops = ['sin', 'cos']

# åŒæ›²å‡½æ•°
hyperbolic_ops = ['sinh', 'cosh', 'tanh']

# ç‰©ç†ç›¸å…³
physics_ops = ['reciprocal']

# ç»„åˆä½¿ç”¨
all_operators = basic_ops + power_ops + log_exp_ops + abs_sign_ops + trig_ops + hyperbolic_ops + physics_ops

model = SissoRegressor(operators=all_operators)
```

#### è‡ªå®šä¹‰æ“ä½œç¬¦è¯¦ç»†ç¤ºä¾‹

```python
import numpy as np

# å®šä¹‰è‡ªå®šä¹‰å‡½æ•°
def exp_decay(x, decay_rate=0.1):
    """æŒ‡æ•°è¡°å‡å‡½æ•°"""
    return np.exp(-decay_rate * np.abs(x))

def polynomial_custom(x, degree=3):
    """è‡ªå®šä¹‰å¤šé¡¹å¼"""
    return x ** degree

def combined_function(x, y):
    """ç»„åˆå‡½æ•°"""
    return np.sqrt(x**2 + y**2)

# æ–¹å¼1ï¼šç›´æ¥ä¼ å…¥ï¼ˆä½¿ç”¨é»˜è®¤è®¾ç½®ï¼‰
model = SissoRegressor(
    operators=[
        '+', '-', '*', 'safe_div',
        exp_decay,           # é»˜è®¤åç§°: 'exp_decay', å¤æ‚åº¦: 2
        polynomial_custom,   # é»˜è®¤åç§°: 'polynomial_custom', å¤æ‚åº¦: 2
        combined_function    # é»˜è®¤åç§°: 'combined_function', å¤æ‚åº¦: 2
    ]
)

# æ–¹å¼2ï¼šè¯¦ç»†é…ç½®
model = SissoRegressor(
    operators=[
        '+', '-', '*', 'safe_div',
        (exp_decay, {
            'name': 'exp_decay',
            'complexity_cost': 3,
            'validity_checker': lambda x: np.isfinite(x)  # å¯é€‰ï¼šæœ‰æ•ˆæ€§æ£€æŸ¥
        }),
        (polynomial_custom, {
            'name': 'poly_custom',
            'complexity_cost': 4
        }),
        (combined_function, {
            'name': 'norm2d',
            'complexity_cost': 3
        })
    ]
)
```

### ğŸ” ç‰¹å¾ç­›é€‰ç­–ç•¥è¯¦è§£

#### çš®å°”é€Šç›¸å…³æ€§ç­›é€‰

```python
model_pearson = SissoRegressor(
    sis_screener='pearson',
    sis_topk=1000,               # ä¿ç•™ç›¸å…³æ€§æœ€é«˜çš„1000ä¸ªç‰¹å¾
    K=3
)
```

#### äº’ä¿¡æ¯ç­›é€‰

```python
model_mi = SissoRegressor(
    sis_screener='mutual_info',
    sis_topk=800,                # äº’ä¿¡æ¯é€šå¸¸æ›´ä¸¥æ ¼ï¼Œå¯ä»¥ç”¨è¾ƒå°‘çš„ç‰¹å¾æ•°
    K=3
)
```

#### åŠ¨æ€ç­›é€‰ç­–ç•¥

```python
# æ ¹æ®æ•°æ®è§„æ¨¡è°ƒæ•´ç­›é€‰å‚æ•°
n_samples, n_features = X.shape

if n_samples < 100:
    topk = min(500, n_samples * 10)
elif n_samples < 1000:
    topk = min(2000, n_samples * 5)
else:
    topk = min(5000, n_samples * 2)

model = SissoRegressor(
    sis_screener='pearson',
    sis_topk=topk,
    K=min(4, int(np.log2(n_features)) + 1)  # æ ¹æ®ç‰¹å¾æ•°è°ƒæ•´å¤æ‚åº¦
)
```

### ğŸ¯ ç¨€ç–å»ºæ¨¡é…ç½®è¯¦è§£

#### OMP (Orthogonal Matching Pursuit)

```python
model_omp = SissoRegressor(
    so_solver='omp',
    so_max_terms=3,              # æœ€å¤šé€‰æ‹©3ä¸ªç‰¹å¾
    cv=5                         # 5æŠ˜äº¤å‰éªŒè¯
)
```

#### Lasso å›å½’

```python
model_lasso = SissoRegressor(
    so_solver='lasso',
    cv=10,                       # æ›´å¤šçš„äº¤å‰éªŒè¯æŠ˜æ•°
    # Lasso ä¼šè‡ªåŠ¨æ ¹æ®æ­£åˆ™åŒ–å‚æ•°é€‰æ‹©ç‰¹å¾æ•°
)
```

#### ElasticNet å›å½’

```python
model_en = SissoRegressor(
    so_solver='elasticnet',
    cv=5,
    # ElasticNet ç»“åˆäº† L1 å’Œ L2 æ­£åˆ™åŒ–
)
```

#### é«˜çº§ç¨€ç–å»ºæ¨¡é…ç½®

```python
# ä½¿ç”¨äº¤å‰éªŒè¯è‡ªåŠ¨é€‰æ‹©æœ€ä½³å‚æ•°
from sklearn.model_selection import TimeSeriesSplit

model = SissoRegressor(
    so_solver='lasso',
    cv=TimeSeriesSplit(n_splits=5),  # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
)
```

### ğŸƒâ€â™‚ï¸ æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹æµç¨‹

#### åŸºç¡€è®­ç»ƒæµç¨‹

```python
# 1. åˆ›å»ºæ¨¡å‹
model = SissoRegressor(
    K=3,
    operators=['+', '-', '*', 'safe_div', 'sqrt', 'square'],
    sis_screener='pearson',
    sis_topk=1000,
    so_solver='omp',
    so_max_terms=5,
    cv=5,
    random_state=42
)

# 2. è®­ç»ƒæ¨¡å‹
print("å¼€å§‹è®­ç»ƒ...")
model.fit(X, y)
print("è®­ç»ƒå®Œæˆï¼")

# 3. è¿›è¡Œé¢„æµ‹
y_pred = model.predict(X)

# 4. è¯„ä¼°æ€§èƒ½
from sklearn.metrics import mean_squared_error, r2_score
rmse = np.sqrt(mean_squared_error(y, y_pred))
r2 = r2_score(y, y_pred)

print(f"RMSE: {rmse:.4f}")
print(f"RÂ²: {r2:.4f}")
```

#### è®­ç»ƒéªŒè¯åˆ†ç¦»

```python
from sklearn.model_selection import train_test_split

# åˆ†ç¦»è®­ç»ƒå’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒ
model.fit(X_train, y_train)

# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
y_pred_test = model.predict(X_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
test_r2 = r2_score(y_test, y_pred_test)

print(f"æµ‹è¯•é›† RMSE: {test_rmse:.4f}")
print(f"æµ‹è¯•é›† RÂ²: {test_r2:.4f}")
```

### ğŸ“‹ ç»“æœåˆ†æä¸è§£é‡Š

#### è·å–è¯¦ç»†æŠ¥å‘Š

```python
# è·å–å®Œæ•´æŠ¥å‘Š
report = model.explain()

# æ‰“å°æ¨¡å‹é…ç½®
print("=== æ¨¡å‹é…ç½® ===")
config = report['configuration']
for key, value in config.items():
    print(f"{key}: {value}")

# æ‰“å°æœ€ç»ˆå…¬å¼
print("\n=== å‘ç°çš„å…¬å¼ ===")
final_model = report['results']['final_model']
print(f"LaTeX æ ¼å¼: {final_model['formula_latex']}")
print(f"SymPy æ ¼å¼: {final_model['formula_sympy']}")
print(f"æˆªè·: {final_model['intercept']:.4f}")

# æ‰“å°ç‰¹å¾ä¿¡æ¯
print("\n=== é€‰ä¸­çš„ç‰¹å¾ ===")
for i, feature in enumerate(final_model['features'], 1):
    print(f"{i}. {feature['signature']}")
    print(f"   ç³»æ•°: {feature['coefficient']:.4f}")
    print(f"   å¤æ‚åº¦: {feature['complexity']}")
    print(f"   LaTeX: {feature['latex']}")
    print()

# æ‰“å°è¿è¡Œç»Ÿè®¡
print("=== è¿è¡Œç»Ÿè®¡ ===")
run_info = report['run_info']
print(f"ç”Ÿæˆç‰¹å¾æ€»æ•°: {run_info['total_features_generated']}")
print(f"SISåç‰¹å¾æ•°: {run_info['features_after_sis']}")
print(f"æœ€ç»ˆæ¨¡å‹ç‰¹å¾æ•°: {run_info['features_in_final_model']}")
```

#### å¯¼å‡ºç»“æœ

```python
from sisso_py.io import export_to_latex, export_to_sympy, export_to_json

# å¯¼å‡º LaTeX å…¬å¼
latex_formula = export_to_latex(model)
print("LaTeX å…¬å¼:", latex_formula)

# å¯¼å‡º SymPy è¡¨è¾¾å¼
sympy_expr = export_to_sympy(model)
print("SymPy è¡¨è¾¾å¼:", sympy_expr)

# å¯¼å‡ºå®Œæ•´æŠ¥å‘Š
export_to_json(model, "sisso_results.json")
print("å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ° sisso_results.json")

# ä¿å­˜æ¨¡å‹ï¼ˆä½¿ç”¨ pickleï¼‰
import pickle
with open('sisso_model.pkl', 'wb') as f:
    pickle.dump(model, f)
print("æ¨¡å‹å·²ä¿å­˜åˆ° sisso_model.pkl")
```

### ğŸ”¬ ç‰©ç†é‡çº²ä¸€è‡´æ€§æ£€æŸ¥

#### é‡çº²ç³»ç»Ÿè¯´æ˜

SISSO-Py æ”¯æŒåŸºäºå›½é™…å•ä½åˆ¶ï¼ˆSIï¼‰çš„7ä¸ªåŸºæœ¬é‡çº²ï¼š

- **M**: è´¨é‡ (Mass)
- **L**: é•¿åº¦ (Length)
- **T**: æ—¶é—´ (Time)
- **I**: ç”µæµ (Electric Current)
- **Î˜**: æ¸©åº¦ (Temperature)
- **N**: ç‰©è´¨çš„é‡ (Amount of Substance)
- **J**: å‘å…‰å¼ºåº¦ (Luminous Intensity)

#### å¸¸è§é‡çº²å®šä¹‰

```python
from sisso_py.dsl.dimension import Dimension

# åŸºæœ¬é‡çº²
mass_dim = Dimension([1, 0, 0, 0, 0, 0, 0])        # M
length_dim = Dimension([0, 1, 0, 0, 0, 0, 0])      # L
time_dim = Dimension([0, 0, 1, 0, 0, 0, 0])        # T
current_dim = Dimension([0, 0, 0, 1, 0, 0, 0])     # I
temperature_dim = Dimension([0, 0, 0, 0, 1, 0, 0]) # Î˜

# å¤åˆé‡çº²
velocity_dim = Dimension([0, 1, -1, 0, 0, 0, 0])   # L/T
acceleration_dim = Dimension([0, 1, -2, 0, 0, 0, 0]) # L/TÂ²
force_dim = Dimension([1, 1, -2, 0, 0, 0, 0])      # MLTâ»Â² (ç‰›é¡¿)
energy_dim = Dimension([1, 2, -2, 0, 0, 0, 0])     # MLÂ²Tâ»Â² (ç„¦è€³)
power_dim = Dimension([1, 2, -3, 0, 0, 0, 0])      # MLÂ²Tâ»Â³ (ç“¦ç‰¹)
pressure_dim = Dimension([1, -1, -2, 0, 0, 0, 0])  # MLâ»Â¹Tâ»Â² (å¸•æ–¯å¡)

# æ— é‡çº²
dimensionless = Dimension([0, 0, 0, 0, 0, 0, 0])
```

#### å¸¦é‡çº²æ£€æŸ¥çš„å®Œæ•´ç¤ºä¾‹

```python
import numpy as np
import pandas as pd
from sisso_py import SissoRegressor
from sisso_py.dsl.dimension import Dimension

# æ¨¡æ‹Ÿç†æƒ³æ°”ä½“æ•°æ®
np.random.seed(42)
n_samples = 100

# ç”Ÿæˆæ•°æ®
temperature = np.random.uniform(250, 350, n_samples)  # K
volume = np.random.uniform(0.1, 1.0, n_samples)      # mÂ³
n_moles = np.random.uniform(0.5, 2.0, n_samples)     # mol

# ç†æƒ³æ°”ä½“å®šå¾‹: PV = nRT => P = nRT/V
R = 8.314  # æ°”ä½“å¸¸æ•°
pressure = (n_moles * R * temperature / volume) + np.random.normal(0, 100, n_samples)

# åˆ›å»ºæ•°æ®æ¡†
data = pd.DataFrame({
    'temperature': temperature,
    'volume': volume,
    'moles': n_moles,
    'pressure': pressure
})

# å®šä¹‰é‡çº²
temp_dim = Dimension([0, 0, 0, 0, 1, 0, 0])        # Î˜ (æ¸©åº¦)
volume_dim = Dimension([0, 3, 0, 0, 0, 0, 0])      # LÂ³ (ä½“ç§¯)
moles_dim = Dimension([0, 0, 0, 0, 0, 1, 0])       # N (ç‰©è´¨çš„é‡)
pressure_dim = Dimension([1, -1, -2, 0, 0, 0, 0])  # MLâ»Â¹Tâ»Â² (å‹å¼º)

feature_dimensions = {
    'temperature': temp_dim,
    'volume': volume_dim,
    'moles': moles_dim
}

# åˆ›å»ºæ¨¡å‹ï¼ˆå¯ç”¨é‡çº²æ£€æŸ¥ï¼‰
model = SissoRegressor(
    K=3,
    operators=['+', '-', '*', 'safe_div', 'reciprocal'],
    dimensional_check=True,
    sis_topk=500,
    so_max_terms=3,
    random_state=42
)

# å‡†å¤‡æ•°æ®
X = data[['temperature', 'volume', 'moles']]
y = data['pressure']

# è®­ç»ƒï¼ˆä¼ å…¥é‡çº²ä¿¡æ¯ï¼‰
model.fit(X, y, 
          feature_dimensions=feature_dimensions,
          target_dimension=pressure_dim)

# æŸ¥çœ‹ç»“æœ
report = model.explain()
print("å‘ç°çš„å…¬å¼ï¼ˆåº”è¯¥ç±»ä¼¼ PV = nRTï¼‰:")
print(report['results']['final_model']['formula_latex'])
```

### ğŸ”¥ é«˜çº§ä½¿ç”¨æŠ€å·§

#### å¤šç›®æ ‡å¹¶è¡Œè®­ç»ƒ

```python
from concurrent.futures import ProcessPoolExecutor
import pandas as pd

def train_sisso_model(config):
    """è®­ç»ƒå•ä¸ªSISSOæ¨¡å‹çš„å‡½æ•°"""
    X, y, params = config
    model = SissoRegressor(**params)
    model.fit(X, y)
    return model.explain()

# å®šä¹‰å¤šä¸ªé…ç½®
configs = [
    (X, y, {'K': 2, 'so_solver': 'omp', 'so_max_terms': 3}),
    (X, y, {'K': 3, 'so_solver': 'lasso'}),
    (X, y, {'K': 2, 'so_solver': 'elasticnet'}),
]

# å¹¶è¡Œè®­ç»ƒ
with ProcessPoolExecutor(max_workers=3) as executor:
    results = list(executor.map(train_sisso_model, configs))

# æ¯”è¾ƒç»“æœ
for i, result in enumerate(results):
    print(f"é…ç½® {i+1} çš„æœ€ä½³å…¬å¼:")
    print(result['results']['final_model']['formula_latex'])
    print()
```

#### è‡ªé€‚åº”å‚æ•°è°ƒæ•´

```python
def adaptive_sisso_training(X, y, max_complexity=5):
    """è‡ªé€‚åº”è°ƒæ•´SISSOå‚æ•°è¿›è¡Œè®­ç»ƒ"""
    n_samples, n_features = X.shape
    
    best_model = None
    best_score = float('-inf')
    
    for K in range(2, max_complexity + 1):
        # æ ¹æ®æ•°æ®è§„æ¨¡è°ƒæ•´å‚æ•°
        if n_samples < 100:
            sis_topk = min(200, n_samples * 3)
            so_max_terms = min(3, n_features)
        elif n_samples < 500:
            sis_topk = min(1000, n_samples * 2)
            so_max_terms = min(5, n_features)
        else:
            sis_topk = min(2000, n_samples)
            so_max_terms = min(8, n_features)
        
        # è®­ç»ƒæ¨¡å‹
        model = SissoRegressor(
            K=K,
            sis_topk=sis_topk,
            so_max_terms=so_max_terms,
            cv=5,
            random_state=42
        )
        
        try:
            model.fit(X, y)
            
            # è®¡ç®—äº¤å‰éªŒè¯å¾—åˆ†
            from sklearn.model_selection import cross_val_score
            from sklearn.metrics import make_scorer, r2_score
            
            scores = cross_val_score(model, X, y, cv=5, scoring='r2')
            avg_score = np.mean(scores)
            
            print(f"K={K}, TopK={sis_topk}, MaxTerms={so_max_terms}, RÂ²={avg_score:.4f}")
            
            if avg_score > best_score:
                best_score = avg_score
                best_model = model
                
        except Exception as e:
            print(f"K={K} è®­ç»ƒå¤±è´¥: {e}")
            continue
    
    return best_model, best_score

# ä½¿ç”¨è‡ªé€‚åº”è®­ç»ƒ
best_model, best_score = adaptive_sisso_training(X, y)
print(f"\næœ€ä½³æ¨¡å‹ RÂ²: {best_score:.4f}")
print("æœ€ä½³å…¬å¼:", best_model.explain()['results']['final_model']['formula_latex'])
```

#### é›†æˆå­¦ä¹ æ–¹æ³•

```python
from sklearn.ensemble import VotingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor

# åˆ›å»ºå¤šä¸ªSISSOæ¨¡å‹
sisso1 = SissoRegressor(K=2, so_solver='omp', random_state=42)
sisso2 = SissoRegressor(K=3, so_solver='lasso', random_state=43)
sisso3 = SissoRegressor(K=2, so_solver='elasticnet', random_state=44)

# åˆ›å»ºå…¶ä»–åŸºå­¦ä¹ å™¨
rf = RandomForestRegressor(n_estimators=100, random_state=42)
lr = LinearRegression()

# åˆ›å»ºæŠ•ç¥¨å›å½’å™¨
ensemble = VotingRegressor([
    ('sisso_omp', sisso1),
    ('sisso_lasso', sisso2),
    ('sisso_en', sisso3),
    ('rf', rf),
    ('lr', lr)
])

# è®­ç»ƒé›†æˆæ¨¡å‹
ensemble.fit(X, y)
y_pred_ensemble = ensemble.predict(X)

# è¯„ä¼°é›†æˆæ•ˆæœ
from sklearn.metrics import r2_score
ensemble_r2 = r2_score(y, y_pred_ensemble)
print(f"é›†æˆæ¨¡å‹ RÂ²: {ensemble_r2:.4f}")
```

#### æ—¶é—´åºåˆ—æ•°æ®å¤„ç†

```python
from sklearn.model_selection import TimeSeriesSplit

# æ—¶é—´åºåˆ—æ•°æ®ç¤ºä¾‹
np.random.seed(42)
n_points = 500
time = np.linspace(0, 10, n_points)

# ç”Ÿæˆå¸¦è¶‹åŠ¿å’Œå­£èŠ‚æ€§çš„æ—¶é—´åºåˆ—
trend = 0.1 * time
seasonal = 2 * np.sin(2 * np.pi * time)
noise = np.random.normal(0, 0.2, n_points)
ts_data = trend + seasonal + noise

# åˆ›å»ºæ»åç‰¹å¾
def create_lag_features(data, max_lag=5):
    """åˆ›å»ºæ»åç‰¹å¾"""
    df = pd.DataFrame({'y': data})
    
    for lag in range(1, max_lag + 1):
        df[f'y_lag_{lag}'] = df['y'].shift(lag)
    
    # æ·»åŠ æ—¶é—´ç‰¹å¾
    df['time'] = range(len(data))
    df['time_squared'] = df['time'] ** 2
    
    return df.dropna()

# å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®
ts_df = create_lag_features(ts_data, max_lag=3)
X_ts = ts_df.drop('y', axis=1)
y_ts = ts_df['y']

# ä½¿ç”¨æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
tscv = TimeSeriesSplit(n_splits=5)

model_ts = SissoRegressor(
    K=3,
    operators=['+', '-', '*', 'safe_div', 'sin', 'cos'],
    cv=tscv,  # ä½¿ç”¨æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
    sis_topk=500,
    so_max_terms=5
)

model_ts.fit(X_ts, y_ts)

# æŸ¥çœ‹æ—¶é—´åºåˆ—æ¨¡å‹ç»“æœ
ts_report = model_ts.explain()
print("æ—¶é—´åºåˆ—æ¨¡å‹å…¬å¼:")
print(ts_report['results']['final_model']['formula_latex'])
```

### ğŸ’¡ æœ€ä½³å®è·µå’Œæ€§èƒ½ä¼˜åŒ–

#### æ•°æ®é¢„å¤„ç†å»ºè®®

```python
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler

def preprocess_data(X, y, method='standard'):
    """æ•°æ®é¢„å¤„ç†å‡½æ•°"""
    
    # 1. å¤„ç†ç¼ºå¤±å€¼
    X_clean = X.fillna(X.median())
    
    # 2. ç§»é™¤å¸¸é‡åˆ—
    constant_cols = X_clean.columns[X_clean.nunique() <= 1]
    if len(constant_cols) > 0:
        print(f"ç§»é™¤å¸¸é‡åˆ—: {list(constant_cols)}")
        X_clean = X_clean.drop(constant_cols, axis=1)
    
    # 3. æ•°æ®ç¼©æ”¾
    if method == 'standard':
        scaler = StandardScaler()
    elif method == 'robust':
        scaler = RobustScaler()  # å¯¹å¼‚å¸¸å€¼æ›´é²æ£’
    elif method == 'minmax':
        scaler = MinMaxScaler()
    else:
        scaler = None
    
    if scaler:
        X_scaled = pd.DataFrame(
            scaler.fit_transform(X_clean),
            columns=X_clean.columns,
            index=X_clean.index
        )
    else:
        X_scaled = X_clean
    
    # 4. ç§»é™¤é«˜ç›¸å…³ç‰¹å¾
    corr_matrix = X_scaled.corr().abs()
    upper_tri = corr_matrix.where(
        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
    )
    
    high_corr_pairs = [
        column for column in upper_tri.columns 
        if any(upper_tri[column] > 0.95)
    ]
    
    if high_corr_pairs:
        print(f"ç§»é™¤é«˜ç›¸å…³ç‰¹å¾: {high_corr_pairs}")
        X_scaled = X_scaled.drop(high_corr_pairs, axis=1)
    
    return X_scaled, y, scaler

# ä½¿ç”¨é¢„å¤„ç†
X_processed, y_processed, scaler = preprocess_data(X, y, method='robust')
```

#### å†…å­˜ä¼˜åŒ–ç­–ç•¥

```python
def memory_efficient_sisso(X, y, batch_size=1000):
    """å†…å­˜ä¼˜åŒ–çš„SISSOè®­ç»ƒ"""
    
    n_samples = len(X)
    
    if n_samples > 10000:
        # å¤§æ•°æ®é›†ï¼šåˆ†æ‰¹å¤„ç†
        print("æ£€æµ‹åˆ°å¤§æ•°æ®é›†ï¼Œä½¿ç”¨åˆ†æ‰¹å¤„ç†...")
        
        # å…ˆç”¨å°æ ·æœ¬è®­ç»ƒè·å¾—ç‰¹å¾é›†
        sample_idx = np.random.choice(n_samples, min(5000, n_samples), replace=False)
        X_sample = X.iloc[sample_idx]
        y_sample = y.iloc[sample_idx]
        
        # è®­ç»ƒå°æ¨¡å‹è·å–é‡è¦ç‰¹å¾
        small_model = SissoRegressor(
            K=2,
            sis_topk=500,
            so_max_terms=3,
            random_state=42
        )
        small_model.fit(X_sample, y_sample)
        
        # åœ¨å…¨æ•°æ®é›†ä¸Šä½¿ç”¨å‘ç°çš„ç‰¹å¾è¿›è¡Œæœ€ç»ˆè®­ç»ƒ
        important_features = [
            f['signature'] for f in 
            small_model.explain()['results']['final_model']['features']
        ]
        
        print(f"å‘ç°é‡è¦ç‰¹å¾: {important_features}")
        
        # ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°åœ¨å…¨æ•°æ®é›†ä¸Šè®­ç»ƒ
        final_model = SissoRegressor(
            K=3,
            sis_topk=1000,
            so_max_terms=5,
            random_state=42
        )
        final_model.fit(X, y)
        
        return final_model
    
    else:
        # å°æ•°æ®é›†ï¼šæ­£å¸¸å¤„ç†
        model = SissoRegressor(
            K=3,
            sis_topk=min(2000, len(X) * 5),
            so_max_terms=min(8, X.shape[1]),
            random_state=42
        )
        model.fit(X, y)
        return model

# ä½¿ç”¨å†…å­˜ä¼˜åŒ–è®­ç»ƒ
optimized_model = memory_efficient_sisso(X, y)
```

#### ç»“æœéªŒè¯å’Œé²æ£’æ€§æ£€æŸ¥

```python
def validate_sisso_results(model, X, y, n_bootstrap=100):
    """éªŒè¯SISSOç»“æœçš„é²æ£’æ€§"""
    
    from sklearn.utils import resample
    from sklearn.metrics import mean_squared_error, r2_score
    
    results = {
        'formulas': [],
        'r2_scores': [],
        'rmse_scores': [],
        'coefficients': []
    }
    
    print("è¿›è¡ŒBootstrapéªŒè¯...")
    
    for i in tqdm(range(n_bootstrap), desc="Bootstrap Sampling"):
        # é‡é‡‡æ ·
        X_boot, y_boot = resample(X, y, random_state=i)
        
        # è®­ç»ƒæ¨¡å‹
        try:
            boot_model = SissoRegressor(
                K=model.K,
                operators=model.operators,
                sis_screener=model.sis_screener,
                sis_topk=model.sis_topk,
                so_solver=model.so_solver,
                so_max_terms=model.so_max_terms,
                cv=model.cv,
                random_state=i
            )
            boot_model.fit(X_boot, y_boot)
            
            # è¯„ä¼°
            y_pred = boot_model.predict(X_boot)
            r2 = r2_score(y_boot, y_pred)
            rmse = np.sqrt(mean_squared_error(y_boot, y_pred))
            
            # è®°å½•ç»“æœ
            report = boot_model.explain()
            formula = report['results']['final_model']['formula_latex']
            coeffs = [f['coefficient'] for f in report['results']['final_model']['features']]
            
            results['formulas'].append(formula)
            results['r2_scores'].append(r2)
            results['rmse_scores'].append(rmse)
            results['coefficients'].append(coeffs)
            
        except Exception as e:
            continue
    
    # åˆ†æç»“æœ
    print(f"\n=== BootstrapéªŒè¯ç»“æœ (n={len(results['r2_scores'])}) ===")
    print(f"RÂ² å¹³å‡å€¼: {np.mean(results['r2_scores']):.4f} Â± {np.std(results['r2_scores']):.4f}")
    print(f"RMSE å¹³å‡å€¼: {np.mean(results['rmse_scores']):.4f} Â± {np.std(results['rmse_scores']):.4f}")
    
    # ç»Ÿè®¡å…¬å¼å‡ºç°é¢‘ç‡
    from collections import Counter
    formula_counts = Counter(results['formulas'])
    print(f"\næœ€å¸¸è§çš„å…¬å¼ (å‡ºç°æ¬¡æ•°):")
    for formula, count in formula_counts.most_common(5):
        print(f"  {count:3d}x: {formula}")
    
    return results

# è¿›è¡Œé²æ£’æ€§éªŒè¯
validation_results = validate_sisso_results(model, X, y, n_bootstrap=50)
```

### ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ç”¨æ³•

```python
import numpy as np
import pandas as pd
from sisso_py import SissoRegressor

# å‡†å¤‡æ•°æ®
X = pd.DataFrame({
    'x1': np.random.randn(100),
    'x2': np.random.randn(100),
    'x3': np.random.randn(100)
})
y = 2 * X['x1']**2 + 3 * X['x2'] - X['x3'] + np.random.randn(100) * 0.1

# åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
model = SissoRegressor(
    K=3,  # æœ€å¤§å¤æ‚åº¦å±‚æ•°
    operators=['+', '-', '*', 'safe_div', 'sqrt', 'square', 'log'],
    sis_screener='pearson',  # ç­›é€‰æ–¹æ³•
    sis_topk=1000,  # SIS ä¿ç•™ç‰¹å¾æ•°
    so_solver='omp',  # ç¨€ç–æ±‚è§£å™¨
    so_max_terms=5,  # æœ€ç»ˆæ¨¡å‹æœ€å¤§é¡¹æ•°
    cv=5  # äº¤å‰éªŒè¯æŠ˜æ•°
)

# æ‹Ÿåˆæ¨¡å‹
model.fit(X, y)

# é¢„æµ‹
y_pred = model.predict(X)

# è·å–è§£é‡Šå’ŒæŠ¥å‘Š
report = model.explain()
print("æœ€ä½³å…¬å¼:", report['results']['final_model']['formula_latex'])
print("æ¨¡å‹ç³»æ•°:", report['results']['final_model']['features'])
```

### å¸¦ç‰©ç†é‡çº²æ£€æŸ¥çš„ç”¨æ³•

```python
from sisso_py import SissoRegressor
from sisso_py.dsl.dimension import Dimension

# å®šä¹‰ç‰©ç†é‡çº² (è´¨é‡M, é•¿åº¦L, æ—¶é—´T, ç”µæµI, æ¸©åº¦Î˜, ç‰©è´¨é‡N, å‘å…‰å¼ºåº¦J)
length_dim = Dimension([0, 1, 0, 0, 0, 0, 0])  # é•¿åº¦ L
time_dim = Dimension([0, 0, 1, 0, 0, 0, 0])    # æ—¶é—´ T
velocity_dim = Dimension([0, 1, -1, 0, 0, 0, 0])  # é€Ÿåº¦ L/T

# å‡†å¤‡å¸¦é‡çº²çš„æ•°æ®
feature_dimensions = {
    'distance': length_dim,
    'time': time_dim,
    'initial_velocity': velocity_dim
}

model = SissoRegressor(
    K=2,
    dimensional_check=True,  # å¯ç”¨é‡çº²æ£€æŸ¥
    operators=['+', '-', '*', 'safe_div', 'square']
)

# æ‹Ÿåˆæ—¶ä¼ å…¥é‡çº²ä¿¡æ¯
model.fit(X, y, 
          feature_dimensions=feature_dimensions,
          target_dimension=length_dim)  # ç›®æ ‡æ˜¯é•¿åº¦é‡çº²
```

### ä½¿ç”¨è‡ªå®šä¹‰æ“ä½œç¬¦

```python
import numpy as np

def gaussian(x):
    """é«˜æ–¯å‡½æ•°"""
    return np.exp(-x**2)

def sigmoid(x):
    """Sigmoid å‡½æ•°"""
    return 1 / (1 + np.exp(-x))

# æ–¹å¼1: ç›´æ¥ä¼ å…¥å‡½æ•°
model = SissoRegressor(
    K=2,
    operators=[
        '+', '-', '*', 'safe_div',
        gaussian,  # ç›´æ¥ä¼ å…¥å‡½æ•°
        sigmoid
    ]
)

# æ–¹å¼2: ä¼ å…¥å‡½æ•°å’Œé…ç½®çš„å…ƒç»„
model = SissoRegressor(
    K=2,
    operators=[
        '+', '-', '*', 'safe_div',
        (gaussian, {'name': 'gauss', 'complexity_cost': 3}),
        (sigmoid, {'name': 'sig', 'complexity_cost': 4})
    ]
)
```

## ğŸ“Š å®Œæ•´ç¤ºä¾‹

### ä¾‹1ï¼šKepler ç¬¬ä¸‰å®šå¾‹å‘ç°

```python
import numpy as np
import pandas as pd
from sisso_py import SissoRegressor
from sisso_py.dsl.dimension import Dimension

# ç”Ÿæˆå¼€æ™®å‹’å®šå¾‹æ•°æ®: T^2 âˆ a^3
np.random.seed(42)
n_samples = 50

# åŠé•¿è½´ (å¤©æ–‡å•ä½)
a = np.random.uniform(0.5, 5.0, n_samples)
# å‘¨æœŸ (å¹´)ï¼ŒåŠ å…¥å™ªå£°
T = np.sqrt(a**3) + np.random.normal(0, 0.05, n_samples)

# åˆ›å»ºæ•°æ®æ¡†
data = pd.DataFrame({
    'semi_major_axis': a,
    'orbital_period': T
})

# å®šä¹‰é‡çº²
length_dim = Dimension([0, 1, 0, 0, 0, 0, 0])  # L
time_dim = Dimension([0, 0, 1, 0, 0, 0, 0])    # T

feature_dims = {'semi_major_axis': length_dim}
target_dim = time_dim

# è®­ç»ƒæ¨¡å‹
model = SissoRegressor(
    K=3,
    operators=['+', '-', '*', 'safe_div', 'sqrt', 'square', 'poly3'],
    dimensional_check=True,
    sis_topk=500,
    so_max_terms=3
)

X = data[['semi_major_axis']]
y = data['orbital_period']

model.fit(X, y, feature_dimensions=feature_dims, target_dimension=target_dim)

# æŸ¥çœ‹ç»“æœ
report = model.explain()
print("å‘ç°çš„å…¬å¼:", report['results']['final_model']['formula_latex'])
print("å¤æ‚åº¦:", report['run_info']['features_in_final_model'])
```

### ä¾‹2ï¼šæ•°æ®é©±åŠ¨çš„ç‰©ç†å…¬å¼å‘ç°

```python
import numpy as np
import pandas as pd
from sisso_py import SissoRegressor

# æ¨¡æ‹Ÿæ•°æ®ï¼šèƒ½é‡å…¬å¼ E = 1/2 * m * v^2
np.random.seed(123)
n = 200

mass = np.random.uniform(1, 10, n)
velocity = np.random.uniform(0, 20, n)
energy = 0.5 * mass * velocity**2 + np.random.normal(0, 0.1, n)

data = pd.DataFrame({
    'mass': mass,
    'velocity': velocity,
    'energy': energy
})

# ä¸ä½¿ç”¨é‡çº²æ£€æŸ¥çš„ç®€å•æ¨¡å¼
model = SissoRegressor(
    K=3,
    operators=['+', '-', '*', 'safe_div', 'square', 'sqrt'],
    sis_screener='mutual_info',  # ä½¿ç”¨äº’ä¿¡æ¯ç­›é€‰
    sis_topk=1000,
    so_solver='lasso',  # ä½¿ç”¨ Lasso æ±‚è§£å™¨
    so_max_terms=3,
    cv=10
)

X = data[['mass', 'velocity']]
y = data['energy']

model.fit(X, y)

# è·å–è¯¦ç»†æŠ¥å‘Š
report = model.explain()
print("æ¨¡å‹é…ç½®:", report['configuration'])
print("æœ€ç»ˆå…¬å¼:", report['results']['final_model']['formula_latex'])
print("ç‰¹å¾ä¿¡æ¯:")
for feature in report['results']['final_model']['features']:
    print(f"  {feature['signature']}: ç³»æ•°={feature['coefficient']:.4f}, å¤æ‚åº¦={feature['complexity']}")

print(f"\nç”Ÿæˆç‰¹å¾æ€»æ•°: {report['run_info']['total_features_generated']}")
print(f"SISåç‰¹å¾æ•°: {report['run_info']['features_after_sis']}")
print(f"æœ€ç»ˆæ¨¡å‹ç‰¹å¾æ•°: {report['run_info']['features_in_final_model']}")
```

## ğŸ”§ é«˜çº§é…ç½®

### æ“ä½œç¬¦é…ç½®

```python
# å†…ç½®æ“ä½œç¬¦
AVAILABLE_OPERATORS = [
    # åŸºç¡€ä»£æ•°
    '+', '-', '*', 'safe_div',
    
    # å¹‚å’Œæ ¹
    'sqrt', 'cbrt', 'square', 'poly2', 'poly3',
    
    # å¯¹æ•°å’ŒæŒ‡æ•°
    'log', 'log10', 'exp',
    
    # ç»å¯¹å€¼å’Œç¬¦å·
    'abs', 'sign',
    
    # ä¸‰è§’å‡½æ•°
    'sin', 'cos',
    
    # åŒæ›²å‡½æ•°
    'sinh', 'cosh', 'tanh',
    
    # ç‰©ç†ç›¸å…³
    'reciprocal'
]

# è‡ªå®šä¹‰å¤æ‚åº¦æƒé‡
model = SissoRegressor(
    operators=[
        '+',     # å¤æ‚åº¦ 1
        '*',     # å¤æ‚åº¦ 1  
        'sqrt',  # å¤æ‚åº¦ 2
        'log',   # å¤æ‚åº¦ 2
        'sin',   # å¤æ‚åº¦ 3
    ]
)
```

### ç­›é€‰ç­–ç•¥é…ç½®

```python
# ä¸åŒçš„ç‰¹å¾ç­›é€‰æ–¹æ³•
model_pearson = SissoRegressor(sis_screener='pearson')      # çš®å°”é€Šç›¸å…³ç³»æ•°
model_mi = SissoRegressor(sis_screener='mutual_info')       # äº’ä¿¡æ¯

# ç­›é€‰å‚æ•°è°ƒæ•´
model = SissoRegressor(
    sis_topk=2000,      # æ¯å±‚ä¿ç•™çš„ç‰¹å¾æ•°
    K=4,                # æœ€å¤§å±‚æ•°
    so_max_terms=5      # æœ€ç»ˆæ¨¡å‹æœ€å¤§é¡¹æ•°
)
```

### ç¨€ç–æ±‚è§£å™¨é…ç½®

```python
# OMP (Orthogonal Matching Pursuit)
model_omp = SissoRegressor(
    so_solver='omp',
    so_max_terms=3
)

# Lasso
model_lasso = SissoRegressor(
    so_solver='lasso',
    # Lasso ä¼šæ ¹æ® alpha å‚æ•°è‡ªåŠ¨ç¡®å®šç‰¹å¾æ•°
)

# ElasticNet
model_en = SissoRegressor(
    so_solver='elasticnet',
    # ç»“åˆ L1 å’Œ L2 æ­£åˆ™åŒ–
)
```

## ğŸ“ˆ ç»“æœå¯¼å‡ºå’Œå¯è§†åŒ–

### å¯¼å‡ºå…¬å¼

```python
from sisso_py.io import export_to_latex, export_to_sympy, export_to_json

# å¯¼å‡ºä¸º LaTeX
latex_formula = export_to_latex(model)
print("LaTeX å…¬å¼:", latex_formula)

# å¯¼å‡ºä¸º SymPy å¯¹è±¡
sympy_expr = export_to_sympy(model)
print("SymPy è¡¨è¾¾å¼:", sympy_expr)

# å¯¼å‡ºå®Œæ•´æŠ¥å‘Šä¸º JSON
export_to_json(model, "sisso_report.json")
```

### æ•°æ®æ¥å£

```python
from sisso_py.io import load_from_pandas, load_from_numpy

# ä» pandas DataFrame åŠ è½½
df = pd.read_csv("data.csv")
X, y = load_from_pandas(df, target_column='target')

# ä» NumPy æ•°ç»„åŠ è½½
X_np = np.random.randn(100, 3)
y_np = np.random.randn(100)
X, y = load_from_numpy(X_np, y_np, feature_names=['f1', 'f2', 'f3'])
```

## âš™ï¸ æ€§èƒ½ä¼˜åŒ–

### å¹¶è¡Œè®¡ç®—

```python
model = SissoRegressor(
    n_jobs=-1,  # ä½¿ç”¨æ‰€æœ‰å¯ç”¨ CPU æ ¸å¿ƒ
    # n_jobs=4   # æˆ–æŒ‡å®šå…·ä½“æ ¸å¿ƒæ•°
)
```

### å†…å­˜å’Œå¤æ‚åº¦æ§åˆ¶

```python
model = SissoRegressor(
    K=2,                # é™ä½å±‚æ•°å‡å°‘ç‰¹å¾æ•°é‡
    sis_topk=500,       # å‡å°‘ç­›é€‰ç‰¹å¾æ•°
    so_max_terms=3,     # é™åˆ¶æœ€ç»ˆæ¨¡å‹å¤æ‚åº¦
)
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**

   ```python
   # è§£å†³æ–¹æ¡ˆï¼šå‡å°‘ç‰¹å¾ç”Ÿæˆæ•°é‡
   model = SissoRegressor(K=2, sis_topk=500)
   ```

2. **é‡çº²æ£€æŸ¥é”™è¯¯**

   ```python
   # ç¡®ä¿é‡çº²å®šä¹‰æ­£ç¡®
   length_dim = Dimension([0, 1, 0, 0, 0, 0, 0])  # [M, L, T, I, Î˜, N, J]
   ```

3. **æ”¶æ•›é—®é¢˜**

   ```python
   # å°è¯•ä¸åŒçš„æ±‚è§£å™¨
   model = SissoRegressor(so_solver='lasso')  # æˆ– 'elasticnet'
   ```

### è°ƒè¯•æ¨¡å¼

```python
from sisso_py.utils.logging import setup_logging
import logging

# å¯ç”¨è¯¦ç»†æ—¥å¿—
setup_logging(level=logging.DEBUG)

model = SissoRegressor(...)
model.fit(X, y)  # å°†è¾“å‡ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
```

## ğŸ“š API å‚è€ƒ

### SissoRegressor å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| K | int | 2 | æœ€å¤§å¤æ‚åº¦å±‚æ•° |
| operators | List | DEFAULT_OPERATORS | ä½¿ç”¨çš„æ“ä½œç¬¦åˆ—è¡¨ |
| sis_screener | str | 'pearson' | ç‰¹å¾ç­›é€‰æ–¹æ³• |
| sis_topk | int | 2000 | SIS ä¿ç•™çš„ç‰¹å¾æ•° |
| so_solver | str | 'omp' | ç¨€ç–æ±‚è§£å™¨ç±»å‹ |
| so_max_terms | int | 3 | æœ€ç»ˆæ¨¡å‹æœ€å¤§é¡¹æ•° |
| cv | int | 5 | äº¤å‰éªŒè¯æŠ˜æ•° |
| dimensional_check | bool | False | æ˜¯å¦å¯ç”¨é‡çº²æ£€æŸ¥ |
| random_state | int | 42 | éšæœºç§å­ |
| n_jobs | int | -1 | å¹¶è¡Œä½œä¸šæ•° |

### ä¸»è¦æ–¹æ³•

- `fit(X, y, feature_dimensions=None, target_dimension=None)`: è®­ç»ƒæ¨¡å‹
- `predict(X)`: è¿›è¡Œé¢„æµ‹  
- `explain()`: è·å–æ¨¡å‹è§£é‡Šå’ŒæŠ¥å‘Š

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. å¼€å¯ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ Apach è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- æ„Ÿè°¢ SISSO ç®—æ³•çš„åŸå§‹ä½œè€…
- æ„Ÿè°¢ scikit-learn ç¤¾åŒºæä¾›çš„ä¼˜ç§€æœºå™¨å­¦ä¹ æ¡†æ¶
- æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…å’Œç”¨æˆ·çš„æ”¯æŒ

## ğŸ“ è”ç³»æ–¹å¼

- é¡¹ç›®ä¸»é¡µ: <https://github.com/lishuzheng01/sisso-py>
- é—®é¢˜æŠ¥å‘Š: <https://github.com/lishuzheng01/sisso-py/issues>
- é‚®ç®±: <3035326878@qq.com>

---

**SISSO-Py**: è®©ç¬¦å·å›å½’å’Œå…¬å¼å‘ç°å˜å¾—ç®€å•! ğŸš€
