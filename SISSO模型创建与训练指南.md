# SISSOæ¨¡å‹åˆ›å»ºä¸è®­ç»ƒæŒ‡å—

æœ¬æŒ‡å—åŸºäºSISSO-Pyé¡¹ç›®çš„å®é™…ä»£ç ç¤ºä¾‹ï¼Œè¯¦ç»†ä»‹ç»å¦‚ä½•åˆ›å»ºå’Œè®­ç»ƒSISSOç¬¦å·å›å½’æ¨¡å‹ï¼Œé‡ç‚¹å…³æ³¨å‚æ•°é€‰æ‹©ç­–ç•¥å’Œæ¨¡å‹è´¨é‡æå‡æ–¹æ³•ã€‚

## ğŸ“‹ ç›®å½•

- [åŸºç¡€æ¨¡å‹åˆ›å»º](#åŸºç¡€æ¨¡å‹åˆ›å»º)
- [æ ¸å¿ƒå‚æ•°è¯¦è§£](#æ ¸å¿ƒå‚æ•°è¯¦è§£)
- [å‚æ•°é€‰æ‹©ç­–ç•¥](#å‚æ•°é€‰æ‹©ç­–ç•¥)
- [æ¨¡å‹è´¨é‡æå‡æŠ€å·§](#æ¨¡å‹è´¨é‡æå‡æŠ€å·§)
- [å®é™…åº”ç”¨æ¡ˆä¾‹](#å®é™…åº”ç”¨æ¡ˆä¾‹)
- [æ•…éšœæ’é™¤ä¸ä¼˜åŒ–](#æ•…éšœæ’é™¤ä¸ä¼˜åŒ–)
- [æœ€ä½³å®è·µæ€»ç»“](#æœ€ä½³å®è·µæ€»ç»“)

## ğŸš€ åŸºç¡€æ¨¡å‹åˆ›å»º

### æœ€ç®€å•çš„æ¨¡å‹åˆ›å»º

æ ¹æ®é¡¹ç›®ä¸­çš„ `test01.py` ç¤ºä¾‹ï¼š

```python
import numpy as np
import pandas as pd
from sisso_py import SissoRegressor

# å‡†å¤‡æ•°æ®
X = pd.DataFrame({
    'x1': np.random.randn(100),
    'x2': np.random.randn(100),
    'x3': np.random.randn(100)
})
y = 2 * X['x1']**2 + 3 * X['x2'] - X['x3'] + np.random.randn(100) * 0.1

# åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
model = SissoRegressor(
    K=2,  # æœ€å¤§å¤æ‚åº¦å±‚æ•°
    operators=['+', '-', '*', 'safe_div', 'sqrt', 'square', 'log'],
    sis_screener='random',  # ç­›é€‰æ–¹æ³•
    sis_topk=1000,  # SIS ä¿ç•™ç‰¹å¾æ•°
    so_solver='lasso',  # ç¨€ç–æ±‚è§£å™¨
    so_max_terms=2,  # æœ€ç»ˆæ¨¡å‹æœ€å¤§é¡¹æ•°
    cv=5  # äº¤å‰éªŒè¯æŠ˜æ•°
)

# æ‹Ÿåˆæ¨¡å‹
model.fit(X, y)

# é¢„æµ‹å’Œè¯„ä¼°
y_pred = model.predict(X)
report = model.explain()
print(report)
```

### æ”¹è¿›ç‰ˆæ¨¡å‹é…ç½®

åŸºäº `test02_improved.py` çš„ä¼˜åŒ–é…ç½®ï¼š

```python
# è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
np.random.seed(42)

# å‡†å¤‡æ›´å¤§çš„æ•°æ®é›†
n_samples = 500  # å¢åŠ æ ·æœ¬æ•°é‡

# ç®€åŒ–ç›®æ ‡å‡½æ•°ï¼Œå‡å°‘å™ªå£°
y = 2 * X['x1']**2 + 3 * X['x2'] - X['x3'] + np.random.randn(n_samples) * 0.05

# åˆ›å»ºæ›´ä¿å®ˆçš„æ¨¡å‹é…ç½®
model = SissoRegressor(
    K=2,  # é™ä½å¤æ‚åº¦
    operators=['+', '-', '*', 'safe_div', 'square'],  # ç§»é™¤logå’Œsqrtä»¥é¿å…æ•°å€¼é—®é¢˜
    sis_screener='pearson',  # ä½¿ç”¨çš®å°”é€Šç›¸å…³æ€§ç­›é€‰
    sis_topk=500,  # å‡å°‘ç‰¹å¾æ•°é‡
    so_solver='omp',  # ä½¿ç”¨OMPæ±‚è§£å™¨
    so_max_terms=3,  # å‡å°‘æœ€ç»ˆé¡¹æ•°
    cv=5,
    random_state=42
)
```

## ğŸ”§ æ ¸å¿ƒå‚æ•°è¯¦è§£

### K - å¤æ‚åº¦å±‚æ•°

**ä½œç”¨**ï¼šæ§åˆ¶ç‰¹å¾ç”Ÿæˆçš„æ·±åº¦ï¼Œå†³å®šè¡¨è¾¾å¼çš„å¤æ‚åº¦
**å…¸å‹å€¼**ï¼š1-5
**é€‰æ‹©ç­–ç•¥**ï¼š

```python
# å°æ•°æ®é›† (< 100 æ ·æœ¬)
K = 2

# ä¸­ç­‰æ•°æ®é›† (100-1000 æ ·æœ¬)  
K = 3

# å¤§æ•°æ®é›† (> 1000 æ ·æœ¬)
K = min(4, int(np.log2(n_features)) + 1)

# ç¤ºä¾‹ï¼šæ ¹æ®æ•°æ®è§„æ¨¡åŠ¨æ€è°ƒæ•´
n_samples, n_features = X.shape
if n_samples < 100:
    K = 2
elif n_samples < 1000:
    K = 3
else:
    K = min(4, int(np.log2(n_features)) + 1)
```

### operators - æ“ä½œç¬¦é€‰æ‹©

**ä½œç”¨**ï¼šå®šä¹‰å¯ç”¨çš„æ•°å­¦æ“ä½œç¬¦
**æ¨èé…ç½®**ï¼š

```python
# åŸºç¡€é…ç½® (ç¨³å®šæ€§ä¼˜å…ˆ)
basic_ops = ['+', '-', '*', 'safe_div', 'square']

# æ ‡å‡†é…ç½® (å¹³è¡¡æ€§èƒ½ä¸å¤æ‚åº¦)
standard_ops = ['+', '-', '*', 'safe_div', 'sqrt', 'square', 'log']

# æ‰©å±•é…ç½® (åŠŸèƒ½å®Œæ•´)
extended_ops = ['+', '-', '*', 'safe_div', 'sqrt', 'square', 'log', 
                'exp', 'abs', 'sin', 'cos', 'reciprocal']

# ç‰©ç†å»ºæ¨¡ä¸“ç”¨
physics_ops = ['+', '-', '*', 'safe_div', 'sqrt', 'square', 
               'reciprocal', 'poly2', 'poly3']

# ç¤ºä¾‹ï¼šæ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©
if problem_type == 'linear':
    operators = ['+', '-', '*', 'safe_div']
elif problem_type == 'polynomial':
    operators = ['+', '-', '*', 'safe_div', 'square', 'poly3']
elif problem_type == 'physics':
    operators = physics_ops
else:
    operators = standard_ops
```

### sis_screener - ç‰¹å¾ç­›é€‰æ–¹æ³•

æ ¹æ® `SCREENER_METHODS.md`ï¼Œæœ‰8ç§å¯é€‰æ–¹æ³•ï¼š

```python
# æ¨èçš„ç­›é€‰æ–¹æ³•é€‰æ‹©ç­–ç•¥
screener_choice = {
    'æ¢ç´¢é˜¶æ®µ': 'pearson',           # å¿«é€Ÿäº†è§£æ•°æ®ç‰¹å¾
    'çº¿æ€§å…³ç³»': 'f_regression',       # ä¸“é—¨é’ˆå¯¹çº¿æ€§å…³ç³»
    'éçº¿æ€§å…³ç³»': 'mutual_info',      # èƒ½æ•è·å¤æ‚æ¨¡å¼  
    'é«˜ç»´æ•°æ®': 'lasso_path',         # å¤„ç†ç‰¹å¾ç»´åº¦ç¾éš¾
    'ç¨³å¥å»ºæ¨¡': 'combined',           # å¤šè§’åº¦éªŒè¯
    'ç²¾ç¡®å»ºæ¨¡': 'rfe',               # é€’å½’ç‰¹å¾æ¶ˆé™¤
    'åŸºçº¿å¯¹æ¯”': 'random'             # éšæœºåŸºçº¿
}

# ææ–™ç§‘å­¦ç¤ºä¾‹ (æ¥è‡ª test_materials_bulk_modulus.py)
model = SissoRegressor(
    K=5,
    operators=['+', '-', '*', 'safe_div', 'sqrt', 'square', 'log', 'exp', 'abs', 'reciprocal'],
    sis_screener='mutual_info',  # ç”¨äºæ•è·å¤æ‚çš„éçº¿æ€§å…³ç³»
    sis_topk=20,
    so_solver='lasso',
    so_max_terms=2,
    cv=5,
    random_state=42
)
```

### sis_topk - ä¿ç•™ç‰¹å¾æ•°

**åŠ¨æ€è°ƒæ•´ç­–ç•¥**ï¼š

```python
def calculate_optimal_topk(n_samples, n_features):
    """æ ¹æ®æ•°æ®è§„æ¨¡è®¡ç®—æœ€ä¼˜çš„ç‰¹å¾ä¿ç•™æ•°é‡"""
    if n_samples < 100:
        return min(500, n_samples * 10)
    elif n_samples < 1000:
        return min(2000, n_samples * 5)
    else:
        return min(5000, n_samples * 2)

# ä½¿ç”¨ç¤ºä¾‹
optimal_topk = calculate_optimal_topk(len(X), X.shape[1])
model = SissoRegressor(sis_topk=optimal_topk)
```

### so_solver - ç¨€ç–æ±‚è§£å™¨

**é€‰æ‹©ç­–ç•¥**ï¼š

```python
# OMP - ç›´æ¥æ§åˆ¶ç‰¹å¾æ•°é‡
model_omp = SissoRegressor(
    so_solver='omp',
    so_max_terms=3,  # æ˜ç¡®æŒ‡å®šç‰¹å¾æ•°
    cv=5
)

# Lasso - è‡ªåŠ¨ç‰¹å¾é€‰æ‹©
model_lasso = SissoRegressor(
    so_solver='lasso',
    cv=10  # æ›´å¤šäº¤å‰éªŒè¯æŠ˜æ•°
)

# ElasticNet - å¹³è¡¡L1å’ŒL2æ­£åˆ™åŒ–
model_en = SissoRegressor(
    so_solver='elasticnet',
    cv=5
)
```

## ğŸ“ˆ å‚æ•°é€‰æ‹©ç­–ç•¥

### åŸºäºæ•°æ®ç‰¹å¾çš„å‚æ•°é€‰æ‹©

```python
def adaptive_parameter_selection(X, y):
    """åŸºäºæ•°æ®ç‰¹å¾è‡ªé€‚åº”é€‰æ‹©å‚æ•°"""
    n_samples, n_features = X.shape
    
    # æ•°æ®å¤æ‚åº¦è¯„ä¼°
    if n_features <= 5:
        complexity_level = 'simple'
    elif n_features <= 20:
        complexity_level = 'moderate'
    else:
        complexity_level = 'complex'
    
    # æ ·æœ¬è§„æ¨¡è¯„ä¼°
    if n_samples < 100:
        sample_size = 'small'
    elif n_samples < 1000:
        sample_size = 'medium'
    else:
        sample_size = 'large'
    
    # å‚æ•°é…ç½®çŸ©é˜µ
    config_matrix = {
        ('simple', 'small'): {
            'K': 2,
            'operators': ['+', '-', '*', 'safe_div', 'square'],
            'sis_screener': 'pearson',
            'sis_topk': 200,
            'so_solver': 'omp',
            'so_max_terms': 2
        },
        ('simple', 'medium'): {
            'K': 3,
            'operators': ['+', '-', '*', 'safe_div', 'sqrt', 'square'],
            'sis_screener': 'pearson',
            'sis_topk': 500,
            'so_solver': 'omp',
            'so_max_terms': 3
        },
        ('moderate', 'medium'): {
            'K': 3,
            'operators': ['+', '-', '*', 'safe_div', 'sqrt', 'square', 'log'],
            'sis_screener': 'mutual_info',
            'sis_topk': 1000,
            'so_solver': 'lasso',
            'so_max_terms': 4
        },
        ('complex', 'large'): {
            'K': 4,
            'operators': ['+', '-', '*', 'safe_div', 'sqrt', 'square', 'log', 'exp', 'abs'],
            'sis_screener': 'lasso_path',
            'sis_topk': 2000,
            'so_solver': 'elasticnet',
            'so_max_terms': 5
        }
    }
    
    key = (complexity_level, sample_size)
    if key in config_matrix:
        return config_matrix[key]
    else:
        # é»˜è®¤é…ç½®
        return config_matrix[('moderate', 'medium')]

# ä½¿ç”¨ç¤ºä¾‹
config = adaptive_parameter_selection(X, y)
model = SissoRegressor(**config, cv=5, random_state=42)
```

### æ¸è¿›å¼å‚æ•°è°ƒä¼˜

```python
def progressive_tuning(X, y, max_complexity=5):
    """æ¸è¿›å¼å‚æ•°è°ƒä¼˜"""
    best_model = None
    best_score = float('-inf')
    
    for K in range(2, max_complexity + 1):
        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´å…¶ä»–å‚æ•°
        if K <= 2:
            sis_topk = min(500, len(X) * 3)
            so_max_terms = min(3, X.shape[1])
        elif K <= 3:
            sis_topk = min(1000, len(X) * 2)
            so_max_terms = min(5, X.shape[1])
        else:
            sis_topk = min(2000, len(X))
            so_max_terms = min(8, X.shape[1])
        
        model = SissoRegressor(
            K=K,
            sis_topk=sis_topk,
            so_max_terms=so_max_terms,
            cv=5,
            random_state=42
        )
        
        try:
            model.fit(X, y)
            from sklearn.model_selection import cross_val_score
            scores = cross_val_score(model, X, y, cv=5, scoring='r2')
            avg_score = np.mean(scores)
            
            print(f"K={K}, TopK={sis_topk}, MaxTerms={so_max_terms}, RÂ²={avg_score:.4f}")
            
            if avg_score > best_score:
                best_score = avg_score
                best_model = model
                
        except Exception as e:
            print(f"K={K} è®­ç»ƒå¤±è´¥: {e}")
            continue
    
    return best_model, best_score
```

## ğŸ’¡ æ¨¡å‹è´¨é‡æå‡æŠ€å·§

### 1. æ•°æ®é¢„å¤„ç†ä¼˜åŒ–

```python
from sklearn.preprocessing import StandardScaler, RobustScaler

def optimize_data_preprocessing(X, y):
    """ä¼˜åŒ–æ•°æ®é¢„å¤„ç†"""
    
    # 1. å¤„ç†ç¼ºå¤±å€¼
    X_clean = X.fillna(X.median())
    
    # 2. ç§»é™¤å¸¸é‡åˆ—
    constant_cols = X_clean.columns[X_clean.nunique() <= 1]
    if len(constant_cols) > 0:
        print(f"ç§»é™¤å¸¸é‡åˆ—: {list(constant_cols)}")
        X_clean = X_clean.drop(constant_cols, axis=1)
    
    # 3. ç§»é™¤é«˜ç›¸å…³ç‰¹å¾
    corr_matrix = X_clean.corr().abs()
    upper_tri = corr_matrix.where(
        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
    )
    
    high_corr_pairs = [
        column for column in upper_tri.columns 
        if any(upper_tri[column] > 0.95)
    ]
    
    if high_corr_pairs:
        print(f"ç§»é™¤é«˜ç›¸å…³ç‰¹å¾: {high_corr_pairs}")
        X_clean = X_clean.drop(high_corr_pairs, axis=1)
    
    # 4. é²æ£’æ ‡å‡†åŒ–
    scaler = RobustScaler()  # å¯¹å¼‚å¸¸å€¼æ›´é²æ£’
    X_scaled = pd.DataFrame(
        scaler.fit_transform(X_clean),
        columns=X_clean.columns,
        index=X_clean.index
    )
    
    return X_scaled, y, scaler
```

### 2. é›†æˆå­¦ä¹ æå‡æ•ˆæœ

```python
def ensemble_sisso_models(X, y):
    """ä½¿ç”¨é›†æˆå­¦ä¹ æå‡SISSOæ¨¡å‹æ•ˆæœ"""
    from sklearn.ensemble import VotingRegressor
    
    # åˆ›å»ºå¤šä¸ªä¸åŒé…ç½®çš„SISSOæ¨¡å‹
    sisso1 = SissoRegressor(
        K=2, so_solver='omp', sis_screener='pearson', random_state=42
    )
    sisso2 = SissoRegressor(
        K=3, so_solver='lasso', sis_screener='mutual_info', random_state=43
    )
    sisso3 = SissoRegressor(
        K=2, so_solver='elasticnet', sis_screener='lasso_path', random_state=44
    )
    
    # åˆ›å»ºæŠ•ç¥¨å›å½’å™¨
    ensemble = VotingRegressor([
        ('sisso_omp', sisso1),
        ('sisso_lasso', sisso2),
        ('sisso_en', sisso3)
    ])
    
    # è®­ç»ƒé›†æˆæ¨¡å‹
    ensemble.fit(X, y)
    return ensemble
```

### 3. äº¤å‰éªŒè¯ç­–ç•¥ä¼˜åŒ–

```python
from sklearn.model_selection import TimeSeriesSplit, KFold, StratifiedKFold

def optimize_cross_validation(X, y, data_type='regression'):
    """ä¼˜åŒ–äº¤å‰éªŒè¯ç­–ç•¥"""
    
    if data_type == 'time_series':
        # æ—¶é—´åºåˆ—æ•°æ®ä½¿ç”¨TimeSeriesSplit
        cv = TimeSeriesSplit(n_splits=5)
    elif len(y) < 100:
        # å°æ•°æ®é›†ä½¿ç”¨Leave-One-Outæˆ–è¾ƒå°‘æŠ˜æ•°
        cv = min(5, len(y) // 10)
    else:
        # æ ‡å‡†å›å½’ä½¿ç”¨KFold
        cv = KFold(n_splits=5, shuffle=True, random_state=42)
    
    model = SissoRegressor(cv=cv)
    return model
```

### 4. æ¨¡å‹éªŒè¯ä¸é²æ£’æ€§æ£€æŸ¥

```python
def validate_model_robustness(model, X, y, n_bootstrap=50):
    """éªŒè¯æ¨¡å‹é²æ£’æ€§"""
    from sklearn.utils import resample
    from sklearn.metrics import r2_score
    from collections import Counter
    
    results = {
        'formulas': [],
        'r2_scores': [],
        'coefficients': []
    }
    
    print("è¿›è¡ŒBootstrapéªŒè¯...")
    
    for i in range(n_bootstrap):
        # é‡é‡‡æ ·
        X_boot, y_boot = resample(X, y, random_state=i)
        
        # ä½¿ç”¨ç›¸åŒé…ç½®è®­ç»ƒæ–°æ¨¡å‹
        boot_model = SissoRegressor(
            K=model.K,
            operators=model.operators,
            sis_screener=model.sis_screener,
            sis_topk=model.sis_topk,
            so_solver=model.so_solver,
            so_max_terms=model.so_max_terms,
            cv=model.cv,
            random_state=i
        )
        
        try:
            boot_model.fit(X_boot, y_boot)
            y_pred = boot_model.predict(X_boot)
            r2 = r2_score(y_boot, y_pred)
            
            report = boot_model.explain()
            formula = report['results']['final_model']['formula_latex']
            
            results['formulas'].append(formula)
            results['r2_scores'].append(r2)
            
        except Exception:
            continue
    
    # åˆ†æç»“æœ
    print(f"\n=== BootstrapéªŒè¯ç»“æœ (n={len(results['r2_scores'])}) ===")
    print(f"RÂ² å¹³å‡å€¼: {np.mean(results['r2_scores']):.4f} Â± {np.std(results['r2_scores']):.4f}")
    
    # ç»Ÿè®¡å…¬å¼å‡ºç°é¢‘ç‡
    formula_counts = Counter(results['formulas'])
    print(f"\næœ€å¸¸è§çš„å…¬å¼:")
    for formula, count in formula_counts.most_common(3):
        print(f"  {count:3d}x: {formula}")
    
    return results
```

## ğŸ¯ å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šææ–™ç§‘å­¦ - ä½“ç§¯æ¨¡é‡é¢„æµ‹

åŸºäº `test_materials_bulk_modulus.py`ï¼š

```python
def materials_science_config():
    """ææ–™ç§‘å­¦ä¸“ç”¨é…ç½®"""
    return SissoRegressor(
        K=5,  # è¾ƒé«˜å¤æ‚åº¦æ•è·ç‰©ç†å…³ç³»
        operators=['+', '-', '*', 'safe_div', 'sqrt', 'square', 'log', 'exp', 'abs', 'reciprocal'],
        sis_screener='mutual_info',  # æ•è·éçº¿æ€§ç‰©ç†å…³ç³»
        sis_topk=20,  # ææ–™æ•°æ®é€šå¸¸ç‰¹å¾æ•°è¾ƒå°‘
        so_solver='lasso',  # è‡ªåŠ¨ç‰¹å¾é€‰æ‹©
        so_max_terms=2,  # ä¿æŒå…¬å¼ç®€æ´
        cv=5,
        random_state=42
    )
```

### æ¡ˆä¾‹2ï¼šç®€å•å‡½æ•°æ‹Ÿåˆ

åŸºäº `test03.py`ï¼š

```python
def simple_function_fitting():
    """ç®€å•å‡½æ•°æ‹Ÿåˆé…ç½®"""
    return SissoRegressor(
        K=1,  # ä½å¤æ‚åº¦
        operators=['+', '-', '*', 'safe_div', 'sqrt', 'square', 'log', 'exp', 'abs', 
                  'sin', 'cos', 'tan', 'sinh', 'cosh', 'tanh', 'reciprocal'],
        sis_screener='random',
        sis_topk=1000,
        so_solver='omp',  # ç›´æ¥æ§åˆ¶é¡¹æ•°
        so_max_terms=3,
        cv=5
    )
```

## ğŸ› ï¸ æ•…éšœæ’é™¤ä¸ä¼˜åŒ–

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. å†…å­˜ä¸è¶³

```python
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘ç‰¹å¾ç”Ÿæˆæ•°é‡
model = SissoRegressor(
    K=2,                # é™ä½å±‚æ•°
    sis_topk=500,       # å‡å°‘ç­›é€‰ç‰¹å¾æ•°
    so_max_terms=3      # é™åˆ¶æœ€ç»ˆæ¨¡å‹å¤æ‚åº¦
)
```

#### 2. æ”¶æ•›é—®é¢˜

```python
# è§£å†³æ–¹æ¡ˆï¼šå°è¯•ä¸åŒæ±‚è§£å™¨
model = SissoRegressor(
    so_solver='lasso',     # æˆ– 'elasticnet'
    cv=10,                 # å¢åŠ äº¤å‰éªŒè¯æŠ˜æ•°
    random_state=42        # å›ºå®šéšæœºç§å­
)
```

#### 3. è¿‡æ‹Ÿåˆé—®é¢˜

```python
# è§£å†³æ–¹æ¡ˆï¼šå¢åŠ æ­£åˆ™åŒ–
model = SissoRegressor(
    so_max_terms=2,        # å‡å°‘æœ€ç»ˆé¡¹æ•°
    cv=10,                 # æ›´ä¸¥æ ¼çš„äº¤å‰éªŒè¯
    sis_topk=500          # å‡å°‘å€™é€‰ç‰¹å¾æ•°
)
```

### æ€§èƒ½ä¼˜åŒ–

#### å¹¶è¡Œè®¡ç®—

```python
model = SissoRegressor(
    n_jobs=-1,  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
    # n_jobs=4   # æˆ–æŒ‡å®šæ ¸å¿ƒæ•°
)
```

#### å†…å­˜ä¼˜åŒ–

```python
def memory_efficient_training(X, y):
    """å†…å­˜ä¼˜åŒ–è®­ç»ƒ"""
    n_samples = len(X)
    
    if n_samples > 5000:
        # å¤§æ•°æ®é›†ï¼šå…ˆç”¨å°æ ·æœ¬æ¢ç´¢
        sample_idx = np.random.choice(n_samples, 2000, replace=False)
        X_sample = X.iloc[sample_idx]
        y_sample = y.iloc[sample_idx]
        
        # å°æ¨¡å‹æ¢ç´¢
        small_model = SissoRegressor(K=2, sis_topk=500, so_max_terms=3)
        small_model.fit(X_sample, y_sample)
        
        # åœ¨å…¨æ•°æ®é›†ä¸Šä½¿ç”¨ä¿å®ˆå‚æ•°
        final_model = SissoRegressor(K=3, sis_topk=1000, so_max_terms=5)
        final_model.fit(X, y)
        
        return final_model
    else:
        # å°æ•°æ®é›†ï¼šæ­£å¸¸è®­ç»ƒ
        model = SissoRegressor()
        model.fit(X, y)
        return model
```

## ğŸ“Š æœ€ä½³å®è·µæ€»ç»“

### å‚æ•°é€‰æ‹©å†³ç­–æ ‘

```
æ•°æ®è§„æ¨¡
â”œâ”€â”€ å°æ•°æ®é›† (< 100 æ ·æœ¬)
â”‚   â”œâ”€â”€ K = 2
â”‚   â”œâ”€â”€ sis_topk = 200-500
â”‚   â”œâ”€â”€ so_max_terms = 2-3
â”‚   â””â”€â”€ sis_screener = 'pearson'
â”‚
â”œâ”€â”€ ä¸­ç­‰æ•°æ®é›† (100-1000 æ ·æœ¬)
â”‚   â”œâ”€â”€ K = 3
â”‚   â”œâ”€â”€ sis_topk = 500-1000
â”‚   â”œâ”€â”€ so_max_terms = 3-5
â”‚   â””â”€â”€ sis_screener = 'mutual_info'
â”‚
â””â”€â”€ å¤§æ•°æ®é›† (> 1000 æ ·æœ¬)
    â”œâ”€â”€ K = 3-4
    â”œâ”€â”€ sis_topk = 1000-2000
    â”œâ”€â”€ so_max_terms = 5-8
    â””â”€â”€ sis_screener = 'lasso_path'
```

### è´¨é‡æå‡æ£€æŸ¥æ¸…å•

- [ ] **æ•°æ®é¢„å¤„ç†**
  - [ ] å¤„ç†ç¼ºå¤±å€¼
  - [ ] ç§»é™¤å¸¸é‡ç‰¹å¾
  - [ ] å¤„ç†é«˜ç›¸å…³ç‰¹å¾
  - [ ] é€‚å½“çš„æ•°æ®æ ‡å‡†åŒ–

- [ ] **å‚æ•°ä¼˜åŒ–**
  - [ ] æ ¹æ®æ•°æ®è§„æ¨¡é€‰æ‹©Kå€¼
  - [ ] åˆç†é€‰æ‹©æ“ä½œç¬¦é›†åˆ
  - [ ] é€‚é…ç­›é€‰æ–¹æ³•
  - [ ] åŠ¨æ€è°ƒæ•´sis_topk

- [ ] **æ¨¡å‹éªŒè¯**
  - [ ] äº¤å‰éªŒè¯é…ç½®
  - [ ] Bootstrapé²æ£’æ€§æ£€æŸ¥
  - [ ] å¤šé…ç½®å¯¹æ¯”
  - [ ] é›†æˆå­¦ä¹ è€ƒè™‘

- [ ] **ç»“æœåˆ†æ**
  - [ ] å…¬å¼åˆç†æ€§æ£€æŸ¥
  - [ ] ç‰©ç†æ„ä¹‰éªŒè¯ï¼ˆå¦‚é€‚ç”¨ï¼‰
  - [ ] æ³›åŒ–èƒ½åŠ›è¯„ä¼°
  - [ ] å¤æ‚åº¦vsæ€§èƒ½æƒè¡¡

### æ¨èçš„å·¥ä½œæµç¨‹

1. **æ•°æ®æ¢ç´¢é˜¶æ®µ**

   ```python
   # å¿«é€Ÿæ¢ç´¢
   model_explore = SissoRegressor(
       K=2, sis_screener='pearson', sis_topk=500, so_max_terms=3
   )
   ```

2. **æ·±å…¥å»ºæ¨¡é˜¶æ®µ**

   ```python
   # ç²¾ç¡®å»ºæ¨¡
   model_precise = SissoRegressor(
       K=3, sis_screener='mutual_info', sis_topk=1000, so_max_terms=5
   )
   ```

3. **æœ€ç»ˆéªŒè¯é˜¶æ®µ**

   ```python
   # é²æ£’éªŒè¯
   model_robust = SissoRegressor(
       K=3, sis_screener='combined', cv=10, so_solver='elasticnet'
   )
   ```

é€šè¿‡éµå¾ªè¿™äº›æŒ‡å¯¼åŸåˆ™å’Œæœ€ä½³å®è·µï¼Œæ‚¨å¯ä»¥æ˜¾è‘—æå‡SISSOæ¨¡å‹çš„è´¨é‡å’Œå¯é æ€§ï¼Œå‘ç°æ›´å‡†ç¡®ã€æ›´æœ‰ç‰©ç†æ„ä¹‰çš„ç¬¦å·å…¬å¼ã€‚

---

## ğŸ“ å‚è€ƒæ–‡ä»¶

- `test01.py` - åŸºç¡€æ¨¡å‹ç¤ºä¾‹
- `test02_improved.py` - æ”¹è¿›é…ç½®ç¤ºä¾‹  
- `test_materials_bulk_modulus.py` - ææ–™ç§‘å­¦åº”ç”¨æ¡ˆä¾‹
- `SCREENER_METHODS.md` - ç‰¹å¾ç­›é€‰æ–¹æ³•æŒ‡å—
- `README.md` - è¯¦ç»†APIæ–‡æ¡£
